{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens:\n",
    "\n",
    "Entity_2_yyyyymmdd.xlsx file is created where all you need to do is upload it to RIC then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import getpass\n",
    "import win32com.client as win32\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the folder where you wanna do the work\n",
    "### Also ask for the Reporting Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = str(input(\"Please enter the RD (YYYYMMDD): \"))\n",
    "\n",
    "ws = \"0194\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make connection with Oracle DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x210eca2b610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up RAY connection:\n",
    "connection_RAY = create_engine(str(\"oracle://:@OCRPN\"))\n",
    "connection_RAY.execute(\"call pack_context.context_open(to_date('{reporting_date}','YYYYMMDD'),{partition})\".format(\n",
    "                 reporting_date = rd, partition = ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save selection\n",
    "### Also see how much time it took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = pd.read_sql_query(\"\"\"WITH OUTCOME as ( select r.booking_company, r.counterparty_original as counterparty, e1.entity_desc, \n",
    "g1.entity_Code as gcc_code, g1.entity_desc as gcc_name, g1.total_annual_sales as gcc_tas, r.asset_class_original as asset_Class,\n",
    "r.bis_entity_type_original as entity_type, e1.et_code_user, et1.entity_type_desc, i.long_term_Rating, sum(ead_pre_ccf) exposure,\n",
    "sum(rwa) rwa from t_cdr r left join entity e1 on r.counterparty_original = e1.entity_code \n",
    "left join entity_type et1 on e1.et_code_user = et1.entity_type \n",
    "left join issuer_Credit_ratings i on r.counterparty_original = i.entity_code \n",
    "left join esr s on e1.entity_code = s.entity_code \n",
    "left join entity g1 on s.entity_group = g1.entity_code \n",
    "where counterparty_original in ( select s.entity_code from esr s where s.original_entity_class <> s.actual_entity_class and s.actual_entity_class in ('SME','SME_PF') ) and rwa > 0 and i.long_term_rating not like 'CORP%' and i.long_term_rating not like 'SME%' and i.long_term_rating not like 'SLOT%' group by g1.entity_code, g1.entity_desc, g1.total_annual_Sales, r.counterparty_original, r.asset_class_original, r.bis_entity_type_original, e1.et_code_user, et1.entity_type_desc, e1.entity_desc, r.booking_company, i.long_term_Rating UNION select r.booking_company, r.counterparty_new as counterparty, e1.entity_desc, g2.entity_code as gcc_code, g2.entity_desc as gcc_name, g2.total_annual_sales as gcc_tas, r.asset_class_new as asset_class, r.bis_entity_type_new as entity_type, e1.et_code_user, et1.entity_type_desc, i.long_term_Rating, sum(ead_pre_ccf) exposure, sum(rwa) rwa from t_cdr r left join entity e1 on r.counterparty_new = e1.entity_code left join entity_type et1 on e1.et_code_user = et1.entity_type left join issuer_Credit_ratings i on r.counterparty_new = i.entity_code left join esr s on e1.entity_code = s.entity_code left join entity g2 on s.entity_group = g2.entity_code where counterparty_new in ( select s.entity_code from esr s where s.original_entity_class <> s.actual_entity_class and s.actual_entity_class in ('SME','SME_PF') ) and rwa > 0 and i.long_term_rating not like 'CORP%' and i.long_term_rating not like 'SME%' and i.long_term_rating not like 'SLOT%' group by g2.entity_code, g2.entity_desc, g2.total_annual_Sales, r.counterparty_new, r.asset_class_new, r.bis_entity_type_new, e1.et_code_user, et1.entity_type_desc, e1.entity_desc, r.booking_company, i.long_term_Rating ) select o.booking_company, o.counterparty, o.entity_desc as counterparty_name, o.et_code_user, o.entity_type_desc, o.long_term_rating, o.gcc_code, o.gcc_name, o.gcc_tas, o.exposure, o.rwa, case when (s.actual_entity_class = 'SME' and o.entity_type = 'SME_EU') then 'Firm Size Adjustement and SME support factor applied' when (s.actual_entity_class = 'SME' and o.entity_type <> 'SME_EU') then 'Firm Size Adjustement applied' else '**Error**' end as treatment from OUTCOME o left join esr s on o.counterparty = s.entity_Code order by treatment\n",
    "\"\"\", connection_RAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save var in an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WZHARBC\\AppData\\Roaming\\Python\\Python310\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# determining the name of the file\n",
    "file_name = rd + '_2nd_Tas_MC.xlsx'\n",
    "ex_folder = \"Export/\"\n",
    "im_folder = \"Import/\"\n",
    "\n",
    "# saving the excel\n",
    "d.to_excel(ex_folder + file_name, index=False)\n",
    "print('DataFrame is written to Excel File successfully.')\n",
    "\n",
    "#load saved excel file\n",
    "file_saved = load_workbook( filename = ex_folder + file_name)\n",
    "#open workbook\n",
    "file_saved_sheet = file_saved.active\n",
    "\n",
    "\n",
    "#load saved entity file\n",
    "entity = load_workbook( filename = im_folder + \"ENTITY_2_TEMPLATE.xlsm\")\n",
    "#open workbook\n",
    "entity_sheet = entity.active\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n",
      "Upload file to RIC\n"
     ]
    }
   ],
   "source": [
    "rng = range( 2, file_saved_sheet.max_row+1, 1)\n",
    "gcc_codes = []\n",
    "for n in rng:\n",
    "    if file_saved_sheet.cell(row = n, column = 7).value not in gcc_codes:\n",
    "        gcc_codes.append(file_saved_sheet.cell(row = n, column = 7).value)\n",
    "\n",
    "rng_2 = range( 19, len(gcc_codes) + 19, 1)\n",
    "for n in rng_2:\n",
    "    entity_sheet.cell( row = n, column = 1).value = gcc_codes[n-19]\n",
    "    entity_sheet.cell( row = n, column = 7).value = -2\n",
    "    \n",
    "#deleting extra file\n",
    "os.remove(\"Export/\" + rd + \"_2nd_Tas_MC.xlsx\")\n",
    "\n",
    "#save the file\n",
    "entity.save(filename=\"Export/Entity_2_\" + rd + \".xlsx\")\n",
    "print(\"File saved\")\n",
    "print(\"Upload file to RIC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b4d75ac280b6c7c3aa43866cb82dc88915409b55fec83a093dd0284cb58708e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
